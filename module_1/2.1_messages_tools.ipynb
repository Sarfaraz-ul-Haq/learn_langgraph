{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Messages"
      ],
      "metadata": {
        "id": "p9297o2wSF1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain"
      ],
      "metadata": {
        "id": "K04i09OwUZRK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "UdQ5XszFR_Yo",
        "outputId": "447cfd73-1fb3-47fb-eda6-3c676180324f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Sarfaraz\n",
            "\n",
            "What is a GPU ? Give answer in two lines\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Gemini Model\n",
            "\n",
            "A GPU (Graphics Processing Unit) is a specialized electronic                                    circuit designed to rapidly manipulate and generate images,                                    videos, and other visual data.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Sarfaraz\n",
            "\n",
            "What is a CPU ? Give answer in two lines\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "A CPU (Central Processing Unit) is the primary component of a                                    computer that performs most of the processing, executing instructions                                    from programs to carry out tasks.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Sarfaraz\n",
            "\n",
            "Ok I got it\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from pprint import pprint\n",
        "\n",
        "messages = [HumanMessage(content=\"What is a GPU ? Give answer in two lines\", name=\"Sarfaraz\")]\n",
        "\n",
        "messages.append(AIMessage(content=\"A GPU (Graphics Processing Unit) is a specialized electronic \\\n",
        "                                   circuit designed to rapidly manipulate and generate images, \\\n",
        "                                   videos, and other visual data.\", name=\"Gemini Model\"))\n",
        "messages.append(HumanMessage(content=\"What is a CPU ? Give answer in two lines\", name=\"Sarfaraz\"))\n",
        "messages.append(AIMessage(content=\"A CPU (Central Processing Unit) is the primary component of a \\\n",
        "                                   computer that performs most of the processing, executing instructions \\\n",
        "                                   from programs to carry out tasks.\", model=\"Gemini Model\"))\n",
        "messages.append(HumanMessage(content=\"Ok I got it\", name=\"Sarfaraz\"))\n",
        "\n",
        "# print(messages)\n",
        "type(messages)\n",
        "\n",
        "for msg in messages:\n",
        "  msg.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "lxKim8WkXbpQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -U langchain-google-genai"
      ],
      "metadata": {
        "id": "DMU1aBhwXfyx",
        "outputId": "2918df15-b301-4299-8236-ab7a68ea2763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/408.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m399.4/408.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "f-kMOrJbXiT-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_call = llm.invoke(\"Hi\")\n",
        "simple_call"
      ],
      "metadata": {
        "id": "9LqBT3u-XlKE",
        "outputId": "408f8842-dd2b-4cc3-e641-5cbf032c2548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hi! What can I do for you today? \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-143a2806-6714-4161-b7ae-1c0edaa07f10-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = [HumanMessage(content=\"What is your name?\")]\n",
        "result = llm.invoke(message)\n",
        "result"
      ],
      "metadata": {
        "id": "9nUZLc-XXqdC",
        "outputId": "7b2a72f7-d5b7-4ecf-d1e4-e31bd8eb22bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I am a large language model, trained by Google. I don't have a name. \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-a0dca456-e2c8-40ef-9d8f-918bf1fa45e3-0', usage_metadata={'input_tokens': 6, 'output_tokens': 19, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_with_instructions = [\n",
        "                SystemMessage(content=\"You are a helpful assistant! Your name is Gemini.\"),\n",
        "                HumanMessage(content=\"What is your name?\")\n",
        "            ]\n",
        "result = llm.invoke(message_with_instructions)\n",
        "result"
      ],
      "metadata": {
        "id": "CYbZDozuXtUs",
        "outputId": "e287e080-0216-4778-f1da-a46cea89a3e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I am a large language model, trained by Google.  I don't have a name, but you can call me Gemini! 😊 \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-db2a9267-41ac-4f98-b0d0-c63d8853cba7-0', usage_metadata={'input_tokens': 17, 'output_tokens': 28, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = llm.invoke(message)\n",
        "res"
      ],
      "metadata": {
        "id": "GOKXebYoXt7K",
        "outputId": "e6638b15-e7c3-45dd-f9ab-c7168a238502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I am a large language model, trained by Google. I don't have a name. \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-06b22643-bc46-48aa-b790-076f7772fa0c-0', usage_metadata={'input_tokens': 6, 'output_tokens': 19, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}