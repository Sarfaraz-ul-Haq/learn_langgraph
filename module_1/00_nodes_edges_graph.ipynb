{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "l43gC5mycVWt"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -q langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class StateSchema(TypedDict):\n",
        "  message: str"
      ],
      "metadata": {
        "id": "1WK3Lr4NmIcn"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = StateSchema(message=\"I am learning langgraph\")\n",
        "obj"
      ],
      "metadata": {
        "id": "GcprCzHamgDc",
        "outputId": "772c6304-58b5-42cf-9090-d9620ca149d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'I am learning langgraph'}"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj[\"message\"] + \" + langchain\""
      ],
      "metadata": {
        "id": "Q8x76y9kmu0K",
        "outputId": "32607692-3882-49b9-f193-07bc4c51a408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am learning langgraph + langchain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(obj)"
      ],
      "metadata": {
        "id": "xwiKYTqpm2Vu",
        "outputId": "a8ecdcd8-a0cf-4db3-b4f6-a556564d05ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj"
      ],
      "metadata": {
        "id": "RFS3KO1_m4og",
        "outputId": "c0ac39f6-0848-45d4-aa57-8cb39adb47ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'I am learning langgraph'}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj[\"message\"] = obj[\"message\"] + \" + langchain\"\n",
        "obj"
      ],
      "metadata": {
        "id": "RsIeqE_-m8KX",
        "outputId": "d6988f33-05aa-423f-9831-f0e795f415b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'I am learning langgraph + langchain'}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nodes"
      ],
      "metadata": {
        "id": "LsVsL_YZnLq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_node(state: StateSchema):\n",
        "  print(\"NODE 1 STATE:\", state)\n",
        "  return {\"message\": \"I'm learning agentic ai development\"}\n",
        "\n",
        "test_node({\"message\": \"I'm learning ai agent development\"})"
      ],
      "metadata": {
        "id": "LqVKyIbVoKWt",
        "outputId": "b72c15da-5bd5-4ff9-ae1d-b548490b7d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NODE 1 STATE: {'message': \"I'm learning ai agent development\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': \"I'm learning agentic ai development\"}"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def node_1(state: StateSchema) -> StateSchema:\n",
        "  print(\"NODE 1 STATE:\", state)\n",
        "  return {\"message\": state[\"message\"] + \"  I am learning langgraph\"}\n",
        "\n",
        "def node_2(state: StateSchema) -> StateSchema:\n",
        "  print(\"NODE 2 STATE:\", state)\n",
        "  return {\"message\": state[\"message\"] + \"  I am learning langchain\"}\n",
        "\n",
        "def node_3(state: StateSchema) -> StateSchema:\n",
        "  print(\"NODE 3 STATE:\", state)\n",
        "  return {\"message\": state[\"message\"] + \"  I am learning python\"}"
      ],
      "metadata": {
        "id": "LPYrQ80CnK__"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "\n",
        "builder = StateGraph(StateSchema)\n",
        "\n",
        "builder.add_node(\"Node 1\", node_1)\n",
        "builder.add_node(\"Node 2\", node_2)\n",
        "builder.add_node(\"Node 3\", node_3)\n",
        "\n",
        "builder.add_edge(START, \"Node 1\")\n",
        "builder.add_edge(\"Node 1\", \"Node 2\")\n",
        "builder.add_edge(\"Node 2\", \"Node 3\")\n",
        "builder.add_edge(\"Node 3\", END)\n",
        "\n",
        "graph: CompiledStateGraph = builder.compile()"
      ],
      "metadata": {
        "id": "GD1CfOXkrjx6"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(builder)"
      ],
      "metadata": {
        "id": "Q3lJtjUZyhpp",
        "outputId": "430405b9-9fd3-424b-98ff-f4ec3b8bac70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langgraph.graph.state.StateGraph"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langgraph.graph.state.StateGraph</b><br/>def __init__(state_schema: Optional[Type[Any]]=None, config_schema: Optional[Type[Any]]=None, *, input: Optional[Type[Any]]=None, output: Optional[Type[Any]]=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langgraph/graph/state.py</a>A graph whose nodes communicate by reading and writing to a shared state.\n",
              "The signature of each node is State -&gt; Partial&lt;State&gt;.\n",
              "\n",
              "Each state key can optionally be annotated with a reducer function that\n",
              "will be used to aggregate the values of that key received from multiple nodes.\n",
              "The signature of a reducer function is (Value, Value) -&gt; Value.\n",
              "\n",
              "Args:\n",
              "    state_schema (Type[Any]): The schema class that defines the state.\n",
              "    config_schema (Optional[Type[Any]]): The schema class that defines the configuration.\n",
              "        Use this to expose configurable parameters in your API.\n",
              "\n",
              "\n",
              "Examples:\n",
              "    &gt;&gt;&gt; from langchain_core.runnables import RunnableConfig\n",
              "    &gt;&gt;&gt; from typing_extensions import Annotated, TypedDict\n",
              "    &gt;&gt;&gt; from langgraph.checkpoint.memory import MemorySaver\n",
              "    &gt;&gt;&gt; from langgraph.graph import StateGraph\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; def reducer(a: list, b: int | None) -&gt; list:\n",
              "    ...     if b is not None:\n",
              "    ...         return a + [b]\n",
              "    ...     return a\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; class State(TypedDict):\n",
              "    ...     x: Annotated[list, reducer]\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; class ConfigSchema(TypedDict):\n",
              "    ...     r: float\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; graph = StateGraph(State, config_schema=ConfigSchema)\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; def node(state: State, config: RunnableConfig) -&gt; dict:\n",
              "    ...     r = config[&quot;configurable&quot;].get(&quot;r&quot;, 1.0)\n",
              "    ...     x = state[&quot;x&quot;][-1]\n",
              "    ...     next_value = x * r * (1 - x)\n",
              "    ...     return {&quot;x&quot;: next_value}\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; graph.add_node(&quot;A&quot;, node)\n",
              "    &gt;&gt;&gt; graph.set_entry_point(&quot;A&quot;)\n",
              "    &gt;&gt;&gt; graph.set_finish_point(&quot;A&quot;)\n",
              "    &gt;&gt;&gt; compiled = graph.compile()\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; print(compiled.config_specs)\n",
              "    [ConfigurableFieldSpec(id=&#x27;r&#x27;, annotation=&lt;class &#x27;float&#x27;&gt;, name=None, description=None, default=None, is_shared=False, dependencies=None)]\n",
              "    &gt;&gt;&gt;\n",
              "    &gt;&gt;&gt; step1 = compiled.invoke({&quot;x&quot;: 0.5}, {&quot;configurable&quot;: {&quot;r&quot;: 3.0}})\n",
              "    &gt;&gt;&gt; print(step1)\n",
              "    {&#x27;x&#x27;: [0.5, 0.75]}</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 79);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(graph)"
      ],
      "metadata": {
        "id": "xzFYU7i3ycjc",
        "outputId": "b012e247-ee92-475a-c28d-f19a4bdea30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langgraph.graph.state.CompiledStateGraph"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langgraph.graph.state.CompiledStateGraph</b><br/>def __init__(*, builder: Graph, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langgraph/graph/state.py</a>A unit of work that can be invoked, batched, streamed, transformed and composed.\n",
              "\n",
              "Key Methods\n",
              "===========\n",
              "\n",
              "- **invoke/ainvoke**: Transforms a single input into an output.\n",
              "- **batch/abatch**: Efficiently transforms multiple inputs into outputs.\n",
              "- **stream/astream**: Streams output from a single input as it&#x27;s produced.\n",
              "- **astream_log**: Streams output and selected intermediate results from an input.\n",
              "\n",
              "Built-in optimizations:\n",
              "\n",
              "- **Batch**: By default, batch runs invoke() in parallel using a thread pool executor.\n",
              "  Override to optimize batching.\n",
              "\n",
              "- **Async**: Methods with &quot;a&quot; suffix are asynchronous. By default, they execute\n",
              "  the sync counterpart using asyncio&#x27;s thread pool.\n",
              "  Override for native async.\n",
              "\n",
              "All methods accept an optional config argument, which can be used to configure\n",
              "execution, add tags and metadata for tracing and debugging etc.\n",
              "\n",
              "Runnables expose schematic information about their input, output and config via\n",
              "the input_schema property, the output_schema property and config_schema method.\n",
              "\n",
              "LCEL and Composition\n",
              "====================\n",
              "\n",
              "The LangChain Expression Language (LCEL) is a declarative way to compose Runnables\n",
              "into chains. Any chain constructed this way will automatically have sync, async,\n",
              "batch, and streaming support.\n",
              "\n",
              "The main composition primitives are RunnableSequence and RunnableParallel.\n",
              "\n",
              "**RunnableSequence** invokes a series of runnables sequentially, with\n",
              "one Runnable&#x27;s output serving as the next&#x27;s input. Construct using\n",
              "the `|` operator or by passing a list of runnables to RunnableSequence.\n",
              "\n",
              "**RunnableParallel** invokes runnables concurrently, providing the same input\n",
              "to each. Construct it using a dict literal within a sequence or by passing a\n",
              "dict to RunnableParallel.\n",
              "\n",
              "\n",
              "For example,\n",
              "\n",
              ".. code-block:: python\n",
              "\n",
              "    from langchain_core.runnables import RunnableLambda\n",
              "\n",
              "    # A RunnableSequence constructed using the `|` operator\n",
              "    sequence = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * 2)\n",
              "    sequence.invoke(1) # 4\n",
              "    sequence.batch([1, 2, 3]) # [4, 6, 8]\n",
              "\n",
              "\n",
              "    # A sequence that contains a RunnableParallel constructed using a dict literal\n",
              "    sequence = RunnableLambda(lambda x: x + 1) | {\n",
              "        &#x27;mul_2&#x27;: RunnableLambda(lambda x: x * 2),\n",
              "        &#x27;mul_5&#x27;: RunnableLambda(lambda x: x * 5)\n",
              "    }\n",
              "    sequence.invoke(1) # {&#x27;mul_2&#x27;: 4, &#x27;mul_5&#x27;: 10}\n",
              "\n",
              "Standard Methods\n",
              "================\n",
              "\n",
              "All Runnables expose additional methods that can be used to modify their behavior\n",
              "(e.g., add a retry policy, add lifecycle listeners, make them configurable, etc.).\n",
              "\n",
              "These methods will work on any Runnable, including Runnable chains constructed\n",
              "by composing other Runnables. See the individual methods for details.\n",
              "\n",
              "For example,\n",
              "\n",
              ".. code-block:: python\n",
              "\n",
              "    from langchain_core.runnables import RunnableLambda\n",
              "\n",
              "    import random\n",
              "\n",
              "    def add_one(x: int) -&gt; int:\n",
              "        return x + 1\n",
              "\n",
              "\n",
              "    def buggy_double(y: int) -&gt; int:\n",
              "        &#x27;&#x27;&#x27;Buggy code that will fail 70% of the time&#x27;&#x27;&#x27;\n",
              "        if random.random() &gt; 0.3:\n",
              "            print(&#x27;This code failed, and will probably be retried!&#x27;)  # noqa: T201\n",
              "            raise ValueError(&#x27;Triggered buggy code&#x27;)\n",
              "        return y * 2\n",
              "\n",
              "    sequence = (\n",
              "        RunnableLambda(add_one) |\n",
              "        RunnableLambda(buggy_double).with_retry( # Retry on failure\n",
              "            stop_after_attempt=10,\n",
              "            wait_exponential_jitter=False\n",
              "        )\n",
              "    )\n",
              "\n",
              "    print(sequence.input_schema.model_json_schema()) # Show inferred input schema\n",
              "    print(sequence.output_schema.model_json_schema()) # Show inferred output schema\n",
              "    print(sequence.invoke(2)) # invoke the sequence (note the retry above!!)\n",
              "\n",
              "Debugging and tracing\n",
              "=====================\n",
              "\n",
              "As the chains get longer, it can be useful to be able to see intermediate results\n",
              "to debug and trace the chain.\n",
              "\n",
              "You can set the global debug flag to True to enable debug output for all chains:\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.globals import set_debug\n",
              "        set_debug(True)\n",
              "\n",
              "Alternatively, you can pass existing or custom callbacks to any given chain:\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.tracers import ConsoleCallbackHandler\n",
              "\n",
              "        chain.invoke(\n",
              "            ...,\n",
              "            config={&#x27;callbacks&#x27;: [ConsoleCallbackHandler()]}\n",
              "        )\n",
              "\n",
              "For a UI (and much more) checkout LangSmith: https://docs.smith.langchain.com/</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 516);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.get_graph()"
      ],
      "metadata": {
        "id": "gvT_pxFVs17N",
        "outputId": "c62d360c-0350-4676-95f5-f78c2f48cf49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'Node 1': Node(id='Node 1', name='Node 1', data=Node 1(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None), 'Node 2': Node(id='Node 2', name='Node 2', data=Node 2(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None), 'Node 3': Node(id='Node 3', name='Node 3', data=Node 3(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='Node 1', target='Node 2', data=None, conditional=False), Edge(source='Node 2', target='Node 3', data=None, conditional=False), Edge(source='Node 3', target='__end__', data=None, conditional=False), Edge(source='__start__', target='Node 1', data=None, conditional=False)])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "eSYsk4Lns-2c",
        "outputId": "5f8748b4-3ac3-45f4-c0c8-076376b3841c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"message\": \"Hello, I'm learning gen ai fundamentals\"})"
      ],
      "metadata": {
        "id": "hifXVpMJt1fH",
        "outputId": "66e008de-8fcf-4f53-eac6-d9d75274ab8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NODE 1 STATE: {'message': \"Hello, I'm learning gen ai fundamentals\"}\n",
            "NODE 2 STATE: {'message': \"Hello, I'm learning gen ai fundamentals  I am learning langgraph\"}\n",
            "NODE 3 STATE: {'message': \"Hello, I'm learning gen ai fundamentals  I am learning langgraph  I am learning langchain\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': \"Hello, I'm learning gen ai fundamentals  I am learning langgraph  I am learning langchain  I am learning python\"}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now using gemini LLM in nodes in simple workflow"
      ],
      "metadata": {
        "id": "fFO1eA_U25wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain langchain-google-genai"
      ],
      "metadata": {
        "id": "EtqdMr5l3rU6"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(api_key=GEMINI_API_KEY, model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "Nsbr9sF_4pGq"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "class LLMTestState(TypedDict):\n",
        "  prompt: str\n",
        "  output: str\n",
        "\n",
        "def llm_node_1(state: LLMTestState) -> LLMTestState:\n",
        "  print(\"Node 1 State --- \", state)\n",
        "  prompt = state[\"prompt\"]\n",
        "  llm_response: AIMessage = llm.invoke(prompt)\n",
        "  return {\"output\": llm_response.content}\n",
        "\n",
        "def node_2(state: LLMTestState) -> LLMTestState:\n",
        "  print(\"Node 2 State --- \", state)"
      ],
      "metadata": {
        "id": "srhqU8LV1cc_"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(LLMTestState)\n",
        "\n",
        "builder.add_node(\"LLM NODE\", llm_node_1)\n",
        "builder.add_node(\"NODE 2\", node_2)\n",
        "\n",
        "builder.add_edge(START, \"LLM NODE\")\n",
        "builder.add_edge(\"LLM NODE\", \"NODE 2\")\n",
        "builder.add_edge(\"NODE 2\", END)\n",
        "\n",
        "graph: CompiledStateGraph = builder.compile()"
      ],
      "metadata": {
        "id": "tyr688zUy982"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"prompt\": \"Why is the sky blue ?\"})"
      ],
      "metadata": {
        "id": "encwVChbWsKF",
        "outputId": "86503279-2cdd-4fab-973e-bf8087c1d566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 1 State ---  {'prompt': 'Why is the sky blue ?'}\n",
            "Node 2 State ---  {'prompt': 'Why is the sky blue ?', 'output': \"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's how it works:\\n\\n* **Sunlight is made up of all colors of the rainbow.**  This is called the visible light spectrum.\\n* **When sunlight enters the Earth's atmosphere, it interacts with the tiny molecules of air, like nitrogen and oxygen.**\\n* **These molecules scatter the sunlight in all directions.** This is called scattering.\\n* **Shorter wavelengths of light, like blue and violet, are scattered more effectively than longer wavelengths, like red and orange.**\\n* **This means that more blue light is scattered towards our eyes from all directions in the sky.**\\n* **Our eyes are more sensitive to blue light than violet, so we perceive the sky as blue.**\\n\\n**Here's a helpful analogy:**\\n\\nImagine shining a flashlight through a glass of water. The light scatters as it passes through the water, and the shorter wavelengths (blue) are scattered more than the longer wavelengths (red). This is why a glass of water can appear blue in certain lighting conditions.\\n\\n**Why is the sunset red?**\\n\\nAs the sun sets, the sunlight has to travel through more of the atmosphere to reach our eyes. This means that more of the blue light is scattered away, leaving more of the longer wavelengths (red and orange) to reach our eyes. This is why sunsets often appear red or orange.\\n\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'Why is the sky blue ?',\n",
              " 'output': \"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's how it works:\\n\\n* **Sunlight is made up of all colors of the rainbow.**  This is called the visible light spectrum.\\n* **When sunlight enters the Earth's atmosphere, it interacts with the tiny molecules of air, like nitrogen and oxygen.**\\n* **These molecules scatter the sunlight in all directions.** This is called scattering.\\n* **Shorter wavelengths of light, like blue and violet, are scattered more effectively than longer wavelengths, like red and orange.**\\n* **This means that more blue light is scattered towards our eyes from all directions in the sky.**\\n* **Our eyes are more sensitive to blue light than violet, so we perceive the sky as blue.**\\n\\n**Here's a helpful analogy:**\\n\\nImagine shining a flashlight through a glass of water. The light scatters as it passes through the water, and the shorter wavelengths (blue) are scattered more than the longer wavelengths (red). This is why a glass of water can appear blue in certain lighting conditions.\\n\\n**Why is the sunset red?**\\n\\nAs the sun sets, the sunlight has to travel through more of the atmosphere to reach our eyes. This means that more of the blue light is scattered away, leaving more of the longer wavelengths (red and orange) to reach our eyes. This is why sunsets often appear red or orange.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}